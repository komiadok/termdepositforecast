<h1 align="center">ğŸ¦ PrÃ©diction de la souscription d'un dÃ©pÃ´t Ã  terme </h1>

<p align="center">
  <img src="https://github.com/komiadok/termdepositforecast/blob/main/cover_image.jpg" width="550"><br>
  <a href="https://fr.freepik.com/">ğŸ“¸ Freepik</a>
</p>

---

## ğŸ“Œ Objectifs

Lâ€™objectif de ce projet est de dÃ©velopper un modÃ¨le de prÃ©diction de la souscription dâ€™un dÃ©pÃ´t Ã  terme auprÃ¨s des clients dâ€™une banque, en suivant une approche rigoureuse de data science appliquÃ©e au secteur bancaire. Le projet se dÃ©roule en plusieurs Ã©tapes clÃ©s :

1. **Exploration et prÃ©paration des donnÃ©es**
   * Collecte et comprÃ©hension des donnÃ©es clients et transactionnelles.
   * DÃ©tection et gestion des anomalies : valeurs manquantes, incohÃ©rentes ou aberrantes.
   * RÃ©alisation d'un **data cleaning** structurÃ© afin de garantir la qualitÃ© des donnÃ©es avant l'analyse et la modÃ©lisation.
2. **Analyse exploratoire des donnÃ©es (EDA)**
   * Identification des tendances et des patterns significatifs au sein du dataset.
   * Visualisation des distributions, corrÃ©lations et comportements des variables clÃ©s.
   * RÃ©alisation de **tests statistiques** adaptÃ©s (tests t de Student, tests du chiÂ², etc.) pour comprendre les relations entre les variables.
3. **ModÃ©lisation prÃ©dictive**
   * Construction et entraÃ®nement de modÃ¨les de machine learning adaptÃ©s Ã  la prÃ©diction binaire (souscription yes/no)
   * Ã‰valuation et scoring des modÃ¨les Ã  l'aide de mÃ©triques pertinentes (AUC, prÃ©cision, rappel, F1-score).
   * SÃ©lection du modÃ¨le final optimisÃ© pour la performance et la robustesse.
4. DÃ©ploiement et intÃ©gration
   * ImplÃ©mentation d'une **API** permettant de rÃ©aliser des prÃ©dictions sur de nouvelles donnÃ©es clients.
   * Documentation et mise en place d'une architecture reproductible pour l'utilisation et la maintenance du modÃ¨le en production

---

## ğŸ“š DonnÃ©es

Ce jeu de donnÃ©es contient des donnÃ©es liÃ©es aux campagnes marketing direct d'une institution bancaire portugaise. Les campagnes Ã©taient basÃ©s sur des appels tÃ©lÃ©phoniques et elles ont Ã©tÃ© rÃ©alisÃ©es entre mai 2008 et novembre 2010. 
* **Source** : [Bank Marketing Dataset â€” UCI](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)
* **Volume** : 41 188 lignes et 21 colonnes

| Champs         | Description                                                                | Type      |
|----------------|----------------------------------------------------------------------------|-----------|
| age            | Ã‚ge du client                                                              | NumÃ©rique |
| job            | Profession du client                                                       | Texte     |
| marital        | Situation matrimoniale du client                                           | Texte     |
| education      | Niveau d'Ã©tudes du client                                                  | Texte     |
| default        | Le client a-t-il un dÃ©faut de paiement de crÃ©dit ?                         | Texte     |
| housing        | Le client a-t-il un prÃªt immobilier ?                                      | Texte     |
| loan           | Le client a-t-il un prÃªt personnel ?                                       | Texte     |
| contact        | Moyen de communication du client                                           | Texte     |
| month          | Mois du dernier contact avec le client                                     | Texte     |
| day_of_week    | Jour du dernier contact avec le client                                     | Texte     |
| duration       | DurÃ©e du dernier contact avec le client                                    | NumÃ©rique |
| campaign       | Nombre de contacts effectuÃ©s avec le client durant la campagne             | NumÃ©rique |
| pdays          | Nombre de jours Ã©coulÃ©s depuis le dernier contact avec le client           | NumÃ©rique |
| previous       | Nombre de contacts effectuÃ©s avec le client lors de la prÃ©cÃ©dente campagne | NumÃ©rique |
| poutcome       | RÃ©sultat de la prÃ©cÃ©dente campagne marketing avec le client                | Texte     |
| emp.var.rate   | Taux de variation de l'emploi                                              | NumÃ©rique |
| cons.price.idx | Indice des prix Ã  la consommation                                          | NumÃ©rique |
| cons.conf.idx  | Indice de confiance des consommateurs                                      | NumÃ©rique |
| euribor3m      | Taux Euribor Ã  3 mois                                                      | NumÃ©rique |
| nr.employed    | Nombre de personnes actives                                                | NumÃ©rique |
| y              | Le client a-t-il souscrit Ã  un dÃ©pÃ´t Ã  terme ?                             | Texte     |  

---

## ğŸ§° Environnement technique

### ğŸ“‹ PrÃ©requis 

* Installer [Visual Studio Code](https://code.visualstudio.com/)
  > TÃ©lÃ©charger la version correspondante Ã  ton OS (Windows / Mac / Linux)
* Installer [Miniconda](https://www.anaconda.com/download/)
  > Entrer son email et choisir la distribution de Miniconda adaptÃ©e.<br>
  > S'assurer que `(base)` apparaÃ®t devant le chemin du disque dur aprÃ¨s installation.

### ğŸ’» Langage et environnement 

* Python : langage utilisÃ© pour les analyses de donnÃ©es et la modÃ©lisation prÃ©dictive.
* GitHub : plateforme utilisÃ©e pour le versionnage du code et le stockage en ligne du projet.
* Jupyter Notebook (via Miniconda) : environnement interactif utilisÃ© pour lâ€™exploration et la visualisation des donnÃ©es.
* VS Code : environnement de dÃ©veloppement utilisÃ© pour le dÃ©veloppement et le dÃ©ploiement des pipelines.

### ğŸ“¦ Librairies Python utilisÃ©es

* `pandas` : manipulation de donnÃ©es
* `numpy` : traitement numÃ©rique
* `matplotlib` et `seaborn` : visualisations
* `scipy` : donctions statistiques et tests (t-test, chiÂ², etc.)
* `scikit-learn` : pipelines, algorithmes d'apprentissage automatique, mÃ©triques, etc.
* `category_encoders` : encodages catÃ©goriels avancÃ©s
* `xgboost` : algorithme d'apprentissage automatique (performant pour classification binaire)
* `SHAP` et `eli5` : interprÃ©tabilitÃ© des modÃ¨les
* `fastapi` : crÃ©ation d'une API
* `joblib`: sauvegarde et chargement du modÃ¨le entraÃ®nÃ©
* `imbalanced-learn (imblearn.over_sampling)` : gestion du dÃ©sÃ©quilibre des classes
* `pydantic` : validation stricte des donnÃ©es d'entrÃ©e dans l'API
* `typing` : annotations de types pour un code plus robuste et lisible

---

## ğŸ“‚ Organisation du projet

```
termdepositforecast/
â”‚
â”œâ”€â”€ data/                                       # DonnÃ©es du projet     
â”‚   â””â”€â”€ raw/                                    # DonnÃ©es brutes
â”‚       â””â”€â”€ bank-additional-full.csv            # Dataset principal pour l'analyse et l'entraÃ®nement
â”‚       â””â”€â”€ bank-additional.csv                 # Dataset utilisÃ© pour tester l'API
â”‚   â””â”€â”€ outputs/                                # DonnÃ©es de sortie
â”‚       â””â”€â”€ mineurs.csv                         # Extraction des mineurs du jeu de donnÃ©es 
â”œâ”€â”€ notebook/                                   # Notebooks pour exploration et analyses
â”‚   â””â”€â”€ exploration.ipynb                       # Exploration des donnÃ©es
â”‚   â””â”€â”€ eda.ipynb                               # Analyse exploratoire des donnÃ©es
â”œâ”€â”€ pipelines/                                  # Pipelines pour le prÃ©traitement et l'entraÃ®nement des modÃ¨les
â”‚   â””â”€â”€ preprocess.py                           # Pipeline de prÃ©traitement des donnÃ©es
â”œâ”€â”€ utils.py                                    # Fonctions utilitaires rÃ©utilisables
â”œâ”€â”€ environment.yml                             # DÃ©pendances
â”œâ”€â”€ cover_image.jpg                             # Image de couverture du projet
â””â”€â”€ README.md                                   # Documentation du projet
```
